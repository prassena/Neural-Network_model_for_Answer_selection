{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from keras.preprocessing import sequence\n",
    "from flask import Flask, jsonify, request,render_template\n",
    "\n",
    "\n",
    "# https://www.tutorialspoint.com/flask\n",
    "import flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "#loading of keyword\n",
    "Question_keywords = np.load(r'Questin_Answer_10000_keywords/Question_keywords.npy',allow_pickle = True)\n",
    "Answer_keywords = np.load(r'Questin_Answer_10000_keywords/Answer_keywords.npy',allow_pickle = True)\n",
    "\n",
    "#load config & weight of best model\n",
    "with open('Best_model/config_9.p', 'rb') as fp:\n",
    "\tconfig = pickle.load(fp)\n",
    "\n",
    "with open('Best_model/Best_weights_9.p', 'rb') as fp:\n",
    "\tweights = pickle.load(fp)\n",
    "\n",
    "#loading weights to model\n",
    "model = tf.keras.Model.from_config(config)\n",
    "model.set_weights(weights)\n",
    "\n",
    "def final_fun_1(X):\n",
    "    '''Takes in raw data do pre processing and returnes predicted result 0 indicates not correct answer,1 indicates correct answer. each question can have only cone correct answer'''\n",
    "    data = X.copy()\n",
    "    preprocessed_Questions = []\n",
    "\t\n",
    "\t#removel of spcial Charaters\n",
    "    for sentance in (data['Question'].values):\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sentance)\n",
    "        sent = ' '.join(e.lower() for e in sent.split())\n",
    "        preprocessed_Questions.append(sent)\n",
    "    \n",
    "    preprocessed_Answers = []\n",
    "    for sentance in (data['Answer'].values):\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sentance)\n",
    "        sent = ' '.join(e.lower() for e in sent.split())\n",
    "        preprocessed_Answers.append(sent)\n",
    "        \n",
    "    data['Question'] = preprocessed_Questions\n",
    "    data['Answer'] = preprocessed_Answers\n",
    "    \n",
    "    #removel of non keywords\n",
    "    que_which_has_ly_keywords = []\n",
    "    for sentance in data['Question']:\n",
    "        sent = ' '.join(e for e in sentance.split() if e in Question_keywords)\n",
    "        que_which_has_ly_keywords.append(sent)\n",
    "    \n",
    "     \n",
    "    ans_which_has_ly_keywords = []\n",
    "    for sentance in data['Answer']:\n",
    "        sent = ' '.join(e for e in sentance.split() if e in Answer_keywords)\n",
    "        ans_which_has_ly_keywords.append(sent)\n",
    "        \n",
    "    data['Question'] = que_which_has_ly_keywords\n",
    "    data['Answer'] = ans_which_has_ly_keywords\n",
    "        \n",
    "        \n",
    "    #Setting numerical value to each word in questions\n",
    "    ecoded_ques = []\n",
    "    for train_ques in data['Question']:\n",
    "        ecoded_ques.append(list(map(lambda x: list(Question_keywords).index(x)+1,train_ques.split(\" \"))))\n",
    "    \n",
    "    ecoded_ans = []\n",
    "    for train_ans in data['Answer']:\n",
    "        ecoded_ans.append(list(map(lambda x: list(Answer_keywords).index(x)+1,train_ans.split(\" \"))))\n",
    "    \n",
    "    data['Question_vector'] = ecoded_ques\n",
    "    data['Answer_vector'] = ecoded_ans\n",
    "    \n",
    "    \n",
    "    #truncate and/or pad input sequences\n",
    "    Max_Question_length = 24\n",
    "    ques_vect_1 = sequence.pad_sequences(list(data.Question_vector), maxlen=Max_Question_length)\n",
    "    ques_vect = [np.hstack((x,10001)) for x in ques_vect_1]\n",
    "        \n",
    "    # truncate and/or pad input sequences\n",
    "    Max_Answer_length = 163\n",
    "    ans_vect = sequence.pad_sequences(data.Answer_vector, maxlen=Max_Answer_length)\n",
    "    \n",
    "    \n",
    "    ques_vect_ds = tf.data.Dataset.from_tensor_slices((ques_vect)).batch(1024)\n",
    "    ans_vect_ds = tf.data.Dataset.from_tensor_slices((ans_vect)).batch(1024)\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def predict(input_vec):\n",
    "        '''Taks in a batch of vector ,pass it into model and returns the predicted value'''\n",
    "        predictions = model(input_vec, training=False)\n",
    "        return predictions\n",
    "\n",
    "    #stack the output of each batch\n",
    "    def predicted_y(ques_vect,ans_vect):\n",
    "        '''Takes in the a two vector(Question,answe vecror) and returns the predicted result'''\n",
    "        ls = []\n",
    "        for question_batch,ans_batch in zip(ques_vect_ds,ans_vect_ds):\n",
    "            test_ques_vec = question_batch\n",
    "            test_ans_vec = ans_batch\n",
    "            ls.append(predict([test_ques_vec,test_ans_vec]))\n",
    "\n",
    "        pred_y = ls[0]\n",
    "        for i in range(1,len(ls)):\n",
    "            pred_y = np.vstack((pred_y,ls[i]))\n",
    "        return pred_y\n",
    "    \n",
    "    predicted_y = predicted_y(ques_vect_ds,ans_vect_ds)\n",
    "    \n",
    "    for_output = np.zeros_like(predicted_y,dtype = np.int32)\n",
    "    for i in range(0,predicted_y.shape[0],10):\n",
    "        maxi = np.argmax(predicted_y[i:i+10])\n",
    "        for_output[i+maxi] = 1\n",
    "        \n",
    "\n",
    "    return np.array(for_output[:,0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET','POST'])\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/data', methods=['POST'])\n",
    "def data():\n",
    "    if request.method == 'POST':\n",
    "        file = request.form['upload-file']\n",
    "        data = pd.read_csv(file)\n",
    "        data['Result']= final_fun_1(data)\n",
    "\n",
    "\n",
    "        return render_template('data.html',total_data = data.loc[:,['Question','Answer','Respose_number']].to_html() ,data=data[data['Result']==1].loc[:,['Question','Answer','Respose_number']].to_html())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
