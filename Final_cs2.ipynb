{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z0ZPp87h1310",
    "outputId": "bff5b182-b2f7-4566-87bc-2bc71d4cb761"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing import sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GY3qhjsu132k"
   },
   "outputs": [],
   "source": [
    "#loaing Data\n",
    "train_df = pd.read_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "FOujxpmO132v",
    "outputId": "29012fd1-7948-42b3-bed3-859fcc8d1b59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Target</th>\n",
       "      <th>Respose_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>symptoms of a dying mouse</td>\n",
       "      <td>This can be fatal quite quickly to mice. 1  It...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>symptoms of a dying mouse</td>\n",
       "      <td>The symptoms of mites include: 1  excessive sc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>symptoms of a dying mouse</td>\n",
       "      <td>Symptoms of Dog and Cat Poisoning. The symptom...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>symptoms of a dying mouse</td>\n",
       "      <td>The symptoms of mites include: excessive scrat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>symptoms of a dying mouse</td>\n",
       "      <td>Seizures and neurologic symptoms are caused by...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Q_id                   Question  ... Target  Respose_number\n",
       "0  10000  symptoms of a dying mouse  ...    0.0             0.0\n",
       "1  10000  symptoms of a dying mouse  ...    0.0             1.0\n",
       "2  10000  symptoms of a dying mouse  ...    0.0             2.0\n",
       "3  10000  symptoms of a dying mouse  ...    0.0             3.0\n",
       "4  10000  symptoms of a dying mouse  ...    0.0             4.0\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNweo4ZHvKL8"
   },
   "source": [
    "## Function to make predictions made on Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bANoQPwC1329"
   },
   "outputs": [],
   "source": [
    "def final_fun_1(X):\n",
    "    '''Function takes raw data as input and do all preprocessing and returns models prediction'''\n",
    "    data = X.copy()\n",
    "    preprocessed_Questions = []\n",
    "    for sentance in (data['Question'].values):\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sentance)\n",
    "        sent = ' '.join(e.lower() for e in sent.split())\n",
    "        preprocessed_Questions.append(sent)\n",
    "    \n",
    "    preprocessed_Answers = []\n",
    "    for sentance in (data['Answer'].values):\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sentance)\n",
    "        sent = ' '.join(e.lower() for e in sent.split())\n",
    "        preprocessed_Answers.append(sent)\n",
    "        \n",
    "    data['Question'] = preprocessed_Questions\n",
    "    data['Answer'] = preprocessed_Answers\n",
    "    \n",
    "    \n",
    "    Question_keywords = np.load(r'Questin_Answer_10000_keywords/Question_keywords.npy',allow_pickle = True)\n",
    "    Answer_keywords = np.load(r'Questin_Answer_10000_keywords/Answer_keywords.npy',allow_pickle = True)\n",
    "    \n",
    "    que_which_has_ly_keywords = []\n",
    "    for sentance in data['Question']:\n",
    "        sent = ' '.join(e for e in sentance.split() if e in Question_keywords)\n",
    "        que_which_has_ly_keywords.append(sent)\n",
    "    \n",
    "     \n",
    "    ans_which_has_ly_keywords = []\n",
    "    for sentance in data['Answer']:\n",
    "        sent = ' '.join(e for e in sentance.split() if e in Answer_keywords)\n",
    "        ans_which_has_ly_keywords.append(sent)\n",
    "        \n",
    "    data['Question'] = que_which_has_ly_keywords\n",
    "    data['Answer'] = ans_which_has_ly_keywords\n",
    "        \n",
    "        \n",
    "    #Setting numerical value to each word in questions\n",
    "    ecoded_ques = []\n",
    "    for train_ques in data['Question']:\n",
    "        ecoded_ques.append(list(map(lambda x: list(Question_keywords).index(x)+1,train_ques.split(\" \"))))\n",
    "    \n",
    "    ecoded_ans = []\n",
    "    for train_ans in data['Answer']:\n",
    "        ecoded_ans.append(list(map(lambda x: list(Answer_keywords).index(x)+1,train_ans.split(\" \"))))\n",
    "    \n",
    "    data['Question_vector'] = ecoded_ques\n",
    "    data['Answer_vector'] = ecoded_ans\n",
    "    \n",
    "    \n",
    "    #truncate and/or pad input sequences\n",
    "    Max_Question_length = 24\n",
    "    ques_vect_1 = sequence.pad_sequences(list(data.Question_vector), maxlen=Max_Question_length)\n",
    "    ques_vect = [np.hstack((x,10001)) for x in ques_vect_1]\n",
    "        \n",
    "    # truncate and/or pad input sequences\n",
    "    Max_Answer_length = 163\n",
    "    ans_vect = sequence.pad_sequences(data.Answer_vector, maxlen=Max_Answer_length)\n",
    "    \n",
    "    \n",
    "    #load config & weight of best model\n",
    "    with open('Training_Embedding_Layer/Best_model/config.p', 'rb') as fp:\n",
    "        config = pickle.load(fp)\n",
    "\n",
    "    with open('Training_Embedding_Layer/Best_model/Best_weights_initial.p', 'rb') as fp:\n",
    "        weights = pickle.load(fp)\n",
    "\n",
    "    #loading weights to model\n",
    "    import tensorflow as tf\n",
    "    model = tf.keras.Model.from_config(config)\n",
    "    model.set_weights(weights)\n",
    "    \n",
    "    ques_vect_ds = list(tf.data.Dataset.from_tensor_slices((ques_vect)).batch(1024).as_numpy_iterator())\n",
    "    ans_vect_ds = list(tf.data.Dataset.from_tensor_slices((ans_vect)).batch(1024).as_numpy_iterator())\n",
    "    \n",
    "\n",
    "    @tf.function\n",
    "    def predict(input_vec):\n",
    "        '''Taks in a batch of vector ,pass it into model and returns the predicted value'''\n",
    "        predictions = model(input_vec, training=False)\n",
    "        return predictions\n",
    "\n",
    "    #stack the output of each batch\n",
    "    def predicted_y(ques_vect,ans_vect):\n",
    "        '''Takes in the a two vector(Question,answe vecror) and returns the predicted result'''\n",
    "        ls = []\n",
    "        for batch in range(len(ques_vect)):\n",
    "            test_ques_vec = ques_vect[batch]\n",
    "            test_ans_vec = ans_vect[batch]\n",
    "            ls.append(predict([test_ques_vec,test_ans_vec]))\n",
    "\n",
    "        pred_y = ls[0]\n",
    "        for i in range(1,len(ls)):\n",
    "            pred_y = np.vstack((pred_y,ls[i]))\n",
    "        return pred_y\n",
    "    \n",
    "    predicted_y = predicted_y(ques_vect_ds,ans_vect_ds)\n",
    "    \n",
    "    for_output = np.zeros_like(predicted_y,dtype = np.int32)\n",
    "    for i in range(0,predicted_y.shape[0],10):\n",
    "        maxi = np.argmax(predicted_y[i:i+10])\n",
    "        for_output[i+maxi] = 1\n",
    "\n",
    "\n",
    "    return np.array(for_output[:,0]),np.array(predicted_y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "KuPsNRFl133I",
    "outputId": "43a2c20d-ea4e-451d-cfe7-75f00384508b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Value output : \n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "Probablity Value output : \n",
      " [0.13777828 0.12637258 0.15753806 0.1403307  0.1734311  0.1083639\n",
      " 0.10261139 0.13404188 0.17250362 0.1126875  0.04208165 0.14256439\n",
      " 0.23313549 0.04767594 0.09345442 0.10812151 0.21852213 0.04989487\n",
      " 0.05162087 0.07677156 0.13927269 0.1449508  0.09386876 0.101661\n",
      " 0.11374235 0.07400876 0.08601692 0.07550621 0.10349679 0.18773758\n",
      " 0.05309692 0.13235503 0.12124524 0.03648993 0.01339278 0.00440446\n",
      " 0.00372639 0.02458245 0.00892746 0.01411194 0.09807554 0.11666846\n",
      " 0.01803702 0.09841385 0.0498164  0.04485628 0.0987055  0.04379711\n",
      " 0.12001166 0.05062103 0.05347881 0.05677226 0.1159744  0.07599413\n",
      " 0.2465117  0.2759447  0.11140323 0.12944421 0.10867387 0.21454352\n",
      " 0.04676348 0.04299769 0.04698983 0.08341014 0.03593683 0.07478622\n",
      " 0.01936671 0.03458306 0.02661216 0.03158635 0.05073819 0.00720382\n",
      " 0.26920226 0.00859424 0.17309168 0.04718161 0.05065742 0.02413866\n",
      " 0.24628338 0.08027145 0.14149067 0.05458397 0.05996695 0.05391118\n",
      " 0.04221416 0.08059001 0.16859794 0.05396283 0.03126419 0.0618893\n",
      " 0.02045883]\n"
     ]
    }
   ],
   "source": [
    "binary_output,probablity_output = final_fun_1(train_df.iloc[:91,:])\n",
    "print(\"Binary Value output : \\n\", binary_output)\n",
    "print(\"Probablity Value output : \\n\", probablity_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkBcZ5Tgv3eZ"
   },
   "source": [
    "## Function  which returns final_metric computed on X ( Raw Data) and Y (target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_OElRyIMSpi"
   },
   "outputs": [],
   "source": [
    "def final_fun_2(X):\n",
    "    '''Functions takes raw data as input, preprocesses the dat and returns loss'''\n",
    "    data = X.copy()\n",
    "    preprocessed_Questions = []\n",
    "    for sentance in (data['Question'].values):\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sentance)\n",
    "        sent = ' '.join(e.lower() for e in sent.split())\n",
    "        preprocessed_Questions.append(sent)\n",
    "    \n",
    "    preprocessed_Answers = []\n",
    "    for sentance in (data['Answer'].values):\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sentance)\n",
    "        sent = ' '.join(e.lower() for e in sent.split())\n",
    "        preprocessed_Answers.append(sent)\n",
    "        \n",
    "    data['Question'] = preprocessed_Questions\n",
    "    data['Answer'] = preprocessed_Answers\n",
    "    \n",
    "    \n",
    "    Question_keywords = np.load(r'Questin_Answer_10000_keywords/Question_keywords.npy',allow_pickle = True)\n",
    "    Answer_keywords = np.load(r'Questin_Answer_10000_keywords/Answer_keywords.npy',allow_pickle = True)\n",
    "    \n",
    "    que_which_has_ly_keywords = []\n",
    "    for sentance in data['Question']:\n",
    "        sent = ' '.join(e for e in sentance.split() if e in Question_keywords)\n",
    "        que_which_has_ly_keywords.append(sent)\n",
    "    \n",
    "     \n",
    "    ans_which_has_ly_keywords = []\n",
    "    for sentance in data['Answer']:\n",
    "        sent = ' '.join(e for e in sentance.split() if e in Answer_keywords)\n",
    "        ans_which_has_ly_keywords.append(sent)\n",
    "        \n",
    "    data['Question'] = que_which_has_ly_keywords\n",
    "    data['Answer'] = ans_which_has_ly_keywords\n",
    "        \n",
    "        \n",
    "    #Setting numerical value to each word in questions\n",
    "    ecoded_ques = []\n",
    "    for train_ques in data['Question']:\n",
    "        ecoded_ques.append(list(map(lambda x: list(Question_keywords).index(x)+1,train_ques.split(\" \"))))\n",
    "    \n",
    "    ecoded_ans = []\n",
    "    for train_ans in data['Answer']:\n",
    "        ecoded_ans.append(list(map(lambda x: list(Answer_keywords).index(x)+1,train_ans.split(\" \"))))\n",
    "    \n",
    "    data['Question_vector'] = ecoded_ques\n",
    "    data['Answer_vector'] = ecoded_ans\n",
    "    \n",
    "    \n",
    "    #truncate and/or pad input sequences\n",
    "    Max_Question_length = 24\n",
    "    ques_vect_1 = sequence.pad_sequences(list(data.Question_vector), maxlen=Max_Question_length)\n",
    "    ques_vect = [np.hstack((x,10001)) for x in ques_vect_1]\n",
    "        \n",
    "    # truncate and/or pad input sequences\n",
    "    Max_Answer_length = 163\n",
    "    ans_vect = sequence.pad_sequences(data.Answer_vector, maxlen=Max_Answer_length)\n",
    "    \n",
    "    \n",
    "    #load config & weight of best model\n",
    "    with open('Training_Embedding_Layer/Best_model/config.p', 'rb') as fp:\n",
    "        config = pickle.load(fp)\n",
    "\n",
    "    with open('Training_Embedding_Layer/Best_model/Best_weights_initial.p', 'rb') as fp:\n",
    "        weights = pickle.load(fp)\n",
    "\n",
    "    #loading weights to model\n",
    "    import tensorflow as tf\n",
    "    model = tf.keras.Model.from_config(config)\n",
    "    model.set_weights(weights)\n",
    "    \n",
    "    ques_vect_ds = list(tf.data.Dataset.from_tensor_slices((ques_vect)).batch(1024).as_numpy_iterator())\n",
    "    ans_vect_ds = list(tf.data.Dataset.from_tensor_slices((ans_vect)).batch(1024).as_numpy_iterator())\n",
    "    target_ds = list(tf.data.Dataset.from_tensor_slices((data.Target)).batch(1024).as_numpy_iterator())\n",
    "\n",
    "    loss = tf.keras.metrics.BinaryCrossentropy(name='loss')\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(input_vec, labels):\n",
    "        # training=False is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(input_vec, training=False)\n",
    "        loss(labels, predictions)\n",
    "\n",
    "    def calculate_loss(ques_vect_ds,ans_vect_ds,target_ds):\n",
    "        for batch in range(len(ques_vect_ds)):\n",
    "            test_ques_vec = ques_vect_ds[batch]\n",
    "            test_ans_vec = ans_vect_ds[batch]\n",
    "            target = target_ds[batch]\n",
    "            test_step([test_ques_vec,test_ans_vec], target)\n",
    "\n",
    "\n",
    "    calculate_loss(ques_vect_ds,ans_vect_ds,target_ds)\n",
    "\n",
    "    return loss.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lom1t8IDS10Y",
    "outputId": "c8be98cf-9f1f-4b71-fc36-459b638f9a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 0.32764858\n"
     ]
    }
   ],
   "source": [
    "loss = final_fun_2(train_df.iloc[:90,:])\n",
    "print(\"Loss :\" , loss)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " Final_cs2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
